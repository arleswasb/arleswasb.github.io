{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51547949",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-09T18:38:04.067101Z",
     "iopub.status.busy": "2025-07-09T18:38:04.066817Z",
     "iopub.status.idle": "2025-07-09T18:38:07.519934Z",
     "shell.execute_reply": "2025-07-09T18:38:07.518982Z"
    },
    "papermill": {
     "duration": 3.45709,
     "end_time": "2025-07-09T18:38:07.521352",
     "exception": false,
     "start_time": "2025-07-09T18:38:04.064262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERRO: O arquivo '/kaggle/input/jogos-completo/DB_completo (1).csv' não foi encontrado.\n",
      "Por favor, certifique-se de que o script Python e o arquivo CSV estão na mesma pasta.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 1. Carregamento e Preparação ---\n",
    "# IMPORTANTE: Coloque sua planilha 'planilha de testes.csv' na mesma pasta que este script.\n",
    "file_path = '/kaggle/input/jogos-completo/DB_completo (1).csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"--- Análise Inicial do Dataset ---\")\n",
    "    print(f\"O dataset possui {df.shape[0]} linhas e {df.shape[1]} colunas.\")\n",
    "    \n",
    "    # Lidando com valores nulos (se houver)\n",
    "    df.dropna(subset=['preco_dolar'], inplace=True) # Remove linhas onde o preço é nulo\n",
    "    for col in ['developers', 'publishers']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('Desconhecido')\n",
    "\n",
    "    # --- 2. Pré-processamento ---\n",
    "    print(\"\\n--- Iniciando Pré-processamento ---\")\n",
    "    target = 'preco_dolar'\n",
    "\n",
    "\n",
    "    # --- NOVO PASSO: Agrupar categorias raras para reduzir a dimensionalidade ---\n",
    "    print(\"\\n--- Agrupando categorias raras ---\")\n",
    "    \n",
    "    # Vamos definir um limite. Qualquer publisher com menos de 20 jogos será 'Outro'.\n",
    "    # Você pode ajustar este número.\n",
    "    min_count_publisher = 20\n",
    "    publishers_counts = df['publishers'].value_counts()\n",
    "    # Pega a lista de publishers que aparecem menos que o limite\n",
    "    rare_publishers = publishers_counts[publishers_counts < min_count_publisher].index\n",
    "    # Substitui todos eles por 'Outro'\n",
    "    df['publishers'] = df['publishers'].replace(rare_publishers, 'Outro')\n",
    "    \n",
    "    \n",
    "    # A mesma lógica para os desenvolvedores\n",
    "    min_count_developer = 20\n",
    "    developers_counts = df['developers'].value_counts()\n",
    "    rare_developers = developers_counts[developers_counts < min_count_developer].index\n",
    "    df['developers'] = df['developers'].replace(rare_developers, 'Outro')\n",
    "    \n",
    "    print(\"Agrupamento concluído!\")\n",
    "    print(\"Novos totais de publishers únicos:\", df['publishers'].nunique())\n",
    "    print(\"Novos totaais de developers únicos:\", df['developers'].nunique())\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Removemos colunas que não ajudam na previsão\n",
    "    features = df.drop(columns=[target, 'preco_euro', 'gameid', 'title'])\n",
    "\n",
    "    # Converter variáveis de texto em numéricas para o modelo entender\n",
    "    X_encoded = pd.get_dummies(features, drop_first=True)\n",
    "    y = df[target]\n",
    "\n",
    "    print(f\"Dimensões de X após encoding: {X_encoded.shape}\")\n",
    "\n",
    "    # --- 3. Divisão dos Dados em Treino e Teste ---\n",
    "    # 80% para treinar, 20% para testar\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "    print(f\"\\nDados divididos: {len(X_train)} para treino, {len(X_test)} para teste.\")\n",
    "\n",
    "    # --- 4. Treinamento do Modelo Random Forest ---\n",
    "    print(\"\\n--- Treinando o Modelo Random Forest Regressor ---\")\n",
    "    # n_estimators=100 significa que o modelo é uma \"floresta\" de 100 \"árvores\" de decisão.\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    print(\"Modelo treinado com sucesso!\")\n",
    "\n",
    "    # --- 5. Avaliação do Modelo ---\n",
    "    print(\"\\n--- Avaliando a Performance do Modelo ---\")\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Erro Médio Absoluto (MAE): ${mae:.2f}\")\n",
    "    print(f\"R-squared (R²): {r2:.2f}\")\n",
    "\n",
    "    # --- 6. Importância das Variáveis (Feature Importances) ---\n",
    "    print(\"\\n--- Análise das Variáveis Mais Importantes ---\")\n",
    "    importances = rf_model.feature_importances_\n",
    "    feature_names = X_encoded.columns\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "    \n",
    "    # Pegando as 15 features mais importantes\n",
    "    top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(15)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=top_features, palette='viridis')\n",
    "    plt.title('Top 15 Variáveis Mais Importantes para Prever o Preço')\n",
    "    plt.xlabel('Importância Relativa')\n",
    "    plt.ylabel('Variável')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: O arquivo '{file_path}' não foi encontrado.\")\n",
    "    print(\"Por favor, certifique-se de que o script Python e o arquivo CSV estão na mesma pasta.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro inesperado: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.370025,
   "end_time": "2025-07-09T18:38:08.141532",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-09T18:37:59.771507",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
